# URL Link Collector and Processor

Этот проект состоит из двух консольных приложений на языке Python, которые работают с очередью RabbitMQ для сбора и обработки внутренних ссылок (для одного домена) из веб-страниц. Приложения используют асинхронную обработку и таймауты для управления работой с очередью.

## Описание приложений

1. **Сбор ссылок (`scraper.py`)**:
   - Принимает URL-адрес в качестве аргумента командной строки.
   - Загружает HTML-код страницы и извлекает все внутренние ссылки для этого домена.
   - Сохраняет найденные ссылки в очередь RabbitMQ.

2. **Обработчик ссылок (`worker.py`)**:
   - Это "вечный" асинхронный producer/consumer, который:
     - Извлекает ссылки из очереди RabbitMQ.
     - Находит внутренние ссылки для каждого URL и добавляет их обратно в очередь.
   - Программа прекращает работу, если в течение 10 секунд не поступает новых сообщений в очередь.

## Требования

- Python 3.7+
- RabbitMQ сервер
- Установленные зависимости (см. раздел "Установка")

### Установка и настройка

1. Убедитесь, что у вас установлен Python 3.10 и RabbitMQ.

2. Склонируйте репозиторий и перейдите в директорию проекта:

```bash
git clone https://github.com/IvanovaDaryaV/Message_Queue_RabbitMQ
cd Message_Queue_RabbitMQ
```

3. Установите зависимости (beautifulsoup4, requests, aio-pika)

```bash
pip install -r requirements.txt
```

4. Настройте RabbitMQ

- Убедитесь, что RabbitMQ запущен на localhost
- Настройте переменные окружения для подключения:
  - RABBITMQ_HOST
  - RABBITMQ_PORT
  - RABBITMQ_USER
  - RABBITMQ_PASSWORD


### Запуск приложения

Запустите scraper.py:

```bash
python scraper.py https://docs.python.org/3/index.html
```

Запустите worker.py

```bash
python worker.py
```
